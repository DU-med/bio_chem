{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xgboostを用いて、スプライスされやすい領域とそうでない領域の配列の学習を行う\n",
    "\n",
    "**目的:**<br>\n",
    "スプライシングを受けやすいイントロン領域とそうではないイントロン領域の二群に分割する<br>\n",
    "各イントロンの両側n塩基の塩基配列を取得し、学習データとする<br>\n",
    "教師あり学習であるXGBoostアルゴリズムを用いて、この二群のを分離させるような特徴的な塩基配列部位を同定する<br>\n",
    "<br>\n",
    "\n",
    "**略語**<br>\n",
    "HAVSR: highly variable alternatively spliced<br>\n",
    "LAVSR: Lowly variable alternatively spliced<br><br>\n",
    "\n",
    "**注意点:**<br>\n",
    "XGBClassifierのインスタンスおよびtrain_test_split関数のrandom stateを変更すると結果が異なる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# オリジナルモジュールのインポート\n",
    "from lib.introngap import PileUp\n",
    "from lib.gbkparse import Seq_count\n",
    "\n",
    "# モジュールのインポート\n",
    "import itertools\n",
    "import logomaker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# クラスのインスタンス化\n",
    "gbk = Seq_count()\n",
    "\n",
    "# gbkファイルの読み込み\n",
    "gbk.read_gbk('../data/gbk/human_ttn.gb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 各種変数の設定\n",
    "\n",
    "# 5-prime側の側の末端の塩基\n",
    "left_edge = gbk.exon_list()[42][0]\n",
    "\n",
    "# 3-prime側の側の末端の塩基\n",
    "right_edge = gbk.exon_list()[219][1]\n",
    "\n",
    "# XGBoostに関する変数の設定\n",
    "early_stopping_rounds = 10\n",
    "learning_rate = 0.01\n",
    "max_depth = 8\n",
    "x_random_state = 1\n",
    "s_random_state =  0\n",
    "test_size = 0.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "gbk.transcript_variants()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各種バリアントのIDを取得\n",
    "vars = gbk.get_mrna_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# すべてのイントロンの始点終点のリストを作成\n",
    "all_introns_list = []\n",
    "for i in vars:\n",
    "    g = Seq_count()\n",
    "    g.read_gbk('../data/gbk/human_ttn.gb')\n",
    "    g.set_mrna_id(i)\n",
    "    for j in g.intron_list():\n",
    "        all_introns_list.append(j)\n",
    "introns_list = []\n",
    "for i in all_introns_list:\n",
    "    if not i in introns_list:\n",
    "        introns_list.append(i)\n",
    "introns_list.sort(key=lambda x: x[0])\n",
    "introns_list = [[i,j] for i,j in introns_list if i > left_edge and j < right_edge]\n",
    "introns_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# すべてのエクソンの始点終点のリストを作成\n",
    "all_exons_list = []\n",
    "for i in vars:\n",
    "    g = Seq_count()\n",
    "    g.read_gbk('../data/gbk/human_ttn.gb')\n",
    "    g.set_mrna_id(i)\n",
    "    for j in g.exon_list():\n",
    "        all_exons_list.append(j)\n",
    "exons_list = []\n",
    "for i in all_exons_list:\n",
    "    if not i in exons_list:\n",
    "        exons_list.append(i)\n",
    "exons_list.sort(key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exons_list = [[i,j] for i,j in exons_list if i < right_edge and j > left_edge]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_intron_combinations = []\n",
    "for i, j in itertools.combinations(exons_list, 2):\n",
    "    possible_intron_combinations.append([i[1], j[0]])\n",
    "possible_intron_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = gbk.gDNA_seq()\n",
    "for i in introns_list[-5:]:\n",
    "    print(seq[i[0]:i[0]+10], seq[i[1]-10:i[1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 15\n",
    "existent_intron_combinations = []\n",
    "non_existent_intron_combinations = []\n",
    "for i in possible_intron_combinations:\n",
    "    if i in introns_list:\n",
    "        existent_intron_combinations.append(seq[i[0]:i[0]+n] + seq[i[1]-n:i[1]])\n",
    "    else:\n",
    "        non_existent_intron_combinations.append(seq[i[0]:i[0]+n] + seq[i[1]-n:i[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ワンホットエンコーディングを行う関数\n",
    "def one_hot_encode(seq):\n",
    "    mapping = {'A': [1, 0, 0, 0], 'T': [0, 1, 0, 0], 'G': [0, 0, 1, 0], 'C': [0, 0, 0, 1]}\n",
    "    return np.array([mapping[s] for s in seq]).flatten()\n",
    "\n",
    "# エンコーディングされた配列を準備\n",
    "encoded_sequences_existent = np.array([one_hot_encode(seq) for seq in existent_intron_combinations])\n",
    "encoded_sequences_non_existent = np.array([one_hot_encode(seq) for seq in non_existent_intron_combinations])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データとしてワンホとエンコーディングされた配列を結合しXとする\n",
    "# ラベルをyとして結合する\n",
    "X = pd.DataFrame(np.concatenate([encoded_sequences_existent, encoded_sequences_non_existent]))\n",
    "y = pd.DataFrame(np.concatenate([np.ones(len(encoded_sequences_existent)), np.zeros(len(encoded_sequences_non_existent))]))\n",
    "\n",
    "# XGBoostのインスタンス化\n",
    "model_l = XGBClassifier(early_stopping_rounds=early_stopping_rounds, learning_rate=learning_rate, max_depth=max_depth, random_state=x_random_state)\n",
    "\n",
    "# データの分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=s_random_state)\n",
    "\n",
    "# データをモデルにfitさせる\n",
    "eval_set = [(X_test, y_test)]\n",
    "model_l.fit(X_train, y_train, eval_set=eval_set, verbose=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logomakerを用いてモチーフを可視化\n",
    "base_df = pd.DataFrame(model_l.feature_importances_.reshape(n*2,4))\n",
    "base_df.columns = ['A','T','G','C']\n",
    "crp_logo = logomaker.Logo(base_df, shade_below=.5, fade_below=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin, vmax = 0, 1\n",
    "\n",
    "# ヒートマップの描画\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12, 2))\n",
    "\n",
    "# 最初のヒートマップ\n",
    "l_df = pd.DataFrame([list(i) for i in existent_intron_combinations])\n",
    "sns.heatmap(l_df.apply(pd.Series.value_counts).fillna(0).astype(int)/len(existent_intron_combinations), ax=ax1, cmap=\"viridis\", vmin=vmin, vmax=vmax, cbar=False)\n",
    "ax1.set_title(\"Left edge of introns in HVAS regions\")\n",
    "\n",
    "# 2つ目のヒートマップ\n",
    "r_df = pd.DataFrame([list(i) for i in non_existent_intron_combinations])\n",
    "cax = fig.add_axes([0.92, 0.12, 0.02, 0.76])  # カラーバーの位置とサイズを調整\n",
    "sns.heatmap(r_df.apply(pd.Series.value_counts).fillna(0).astype(int)/len(non_existent_intron_combinations), ax=ax2, cmap=\"viridis\",vmin=vmin, vmax=vmax, cbar_ax=cax)\n",
    "ax2.set_title(\"Right edge of introns in HVAS regions\")\n",
    "\n",
    "# Figureの表示\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
