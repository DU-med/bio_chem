{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xgboostを用いて、スプライスされやすい領域とそうでない領域の配列の学習を行う"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# オリジナルモジュールのインポート\n",
    "from lib.introngap import PileUp\n",
    "from lib.gbkparse import Seq_count\n",
    "\n",
    "# モジュールのインポート\n",
    "import itertools\n",
    "import logomaker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# クラスのインスタンス化\n",
    "gbk = Seq_count()\n",
    "\n",
    "# gbkファイルの読み込み\n",
    "gbk.read_gbk('../data/gbk/human_ttn.gb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 各イントロンの両端n塩基を抽出し下記の条件でデータを分割する\n",
    "スプライシングを受けやすい領域(highs): intron 120-220<br>\n",
    "スプライシングを受けにくい領域(lows): intron 221-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 各イントロンの5-prime側のn塩基にフォーカスし解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各イントロンの両端n塩基を抽出し\n",
    "n = 30\n",
    "\n",
    "# 各イントロンの5-prime側のn塩基を抽出 \n",
    "left_edges = []\n",
    "for i in range(gbk.intron_num()):\n",
    "    left_edges.append(str(gbk.intron_seq(i+1)[:n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 領域の切り出し\n",
    "high_s, high_e = 120, 220\n",
    "low_s, low_e = 0, 45\n",
    "# low_s, low_e = 220, gbk.intron_num()\n",
    "left_edges_high = left_edges[high_s:high_e]\n",
    "left_edge_low = left_edges[low_s:low_e] \n",
    "\n",
    "# ワンホットエンコーディングを行う関数\n",
    "def one_hot_encode(seq):\n",
    "    mapping = {'A': [1, 0, 0, 0], 'T': [0, 1, 0, 0], 'G': [0, 0, 1, 0], 'C': [0, 0, 0, 1]}\n",
    "    return np.array([mapping[s] for s in seq]).flatten()\n",
    "\n",
    "# エンコーディングされた配列を準備\n",
    "encoded_sequences_high = np.array([one_hot_encode(seq) for seq in left_edges_high])\n",
    "encoded_sequences_low = np.array([one_hot_encode(seq) for seq in left_edge_low])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データとしてワンホとエンコーディングされた配列を結合しXとする\n",
    "# ラベルをyとして結合する\n",
    "X = pd.DataFrame(np.concatenate([encoded_sequences_high, encoded_sequences_low]))\n",
    "y = pd.DataFrame(np.concatenate([np.ones(len(encoded_sequences_high)), np.zeros(len(encoded_sequences_low))]))\n",
    "\n",
    "# XGBoostのインスタンス化\n",
    "model = XGBClassifier(early_stopping_rounds=10, learning_rate=0.05, max_depth=8)\n",
    "\n",
    "# データの分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# データをモデルにfitさせる\n",
    "eval_set = [(X_test, y_test)]\n",
    "model.fit(X_train, y_train, eval_set=eval_set, verbose=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logomakerを用いてモチーフを可視化\n",
    "b_df_r = pd.DataFrame(model.feature_importances_.reshape(30,4))\n",
    "b_df_r.columns = ['A','T','G','C']\n",
    "crp_logo = logomaker.Logo(b_df_r, shade_below=.5, fade_below=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_count = 0\n",
    "for i in left_edges_high:\n",
    "    if i[3] == \"A\":\n",
    "        g_count += 1\n",
    "print(g_count/len(left_edges_high))\n",
    "\n",
    "g_count = 0\n",
    "for i in left_edge_low:\n",
    "    if i[3] == \"A\":\n",
    "        g_count += 1\n",
    "print(g_count/len(left_edge_low))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 各イントロンの5-prime側のn塩基にフォーカスし解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# 各イントロンの3-prime側のn塩基を抽出\n",
    "right_edges = []\n",
    "for i in range(gbk.intron_num()):\n",
    "    right_edges.append(str(gbk.intron_seq(i+1)[-n:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 領域の切り出し\n",
    "high_s, high_e = 120, 220\n",
    "low_s, low_e = 0, 45\n",
    "# low_s, low_e = 220, gbk.intron_num()\n",
    "right_edges_high = right_edges[high_s:high_e]\n",
    "right_edges_low = right_edges[low_s:low_e] \n",
    "\n",
    "# ワンホットエンコーディングを行う関数\n",
    "def one_hot_encode(seq):\n",
    "    mapping = {'A': [1, 0, 0, 0], 'T': [0, 1, 0, 0], 'G': [0, 0, 1, 0], 'C': [0, 0, 0, 1]}\n",
    "    return np.array([mapping[s] for s in seq]).flatten()\n",
    "\n",
    "# エンコーディングされた配列を準備\n",
    "encoded_sequences_high = np.array([one_hot_encode(seq) for seq in right_edges_high])\n",
    "encoded_sequences_low = np.array([one_hot_encode(seq) for seq in right_edge_low])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データとしてワンホとエンコーディングされた配列を結合しXとする\n",
    "# ラベルをyとして結合する\n",
    "X = pd.DataFrame(np.concatenate([encoded_sequences_high, encoded_sequences_low]))\n",
    "y = pd.DataFrame(np.concatenate([np.ones(len(encoded_sequences_high)), np.zeros(len(encoded_sequences_low))]))\n",
    "\n",
    "# XGBoostのインスタンス化\n",
    "model = XGBClassifier(early_stopping_rounds=10, learning_rate=0.1, max_depth=8)\n",
    "\n",
    "# データの分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# データをモデルにfitさせる\n",
    "eval_set = [(X_test, y_test)]\n",
    "model.fit(X_train, y_train, eval_set=eval_set, verbose=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logomakerを用いてモチーフを可視化\n",
    "b_df_r = pd.DataFrame(model.feature_importances_.reshape(30,4))\n",
    "b_df_r.columns = ['A','T','G','C']\n",
    "crp_logo = logomaker.Logo(b_df_r, shade_below=.5, fade_below=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_count = 0\n",
    "for i in right_edges_high:\n",
    "    print(i)\n",
    "    if i[27] == \"A\":\n",
    "        g_count += 1\n",
    "print(g_count/len(right_edges_high))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "g_count = 0\n",
    "for i in right_edges_low:\n",
    "    print(i)\n",
    "    if i[27] == \"A\":\n",
    "        g_count += 1\n",
    "print(g_count/len(right_edge_low))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
